{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efbbc9a7-cf0e-4172-8ec1-110630151180",
   "metadata": {},
   "source": [
    "# Plant Disease Detection - Deep Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f294530-ccec-4d93-983f-8afc88f0d2bb",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c8e00e-4921-47d2-93c2-adcc84a25927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Dict, List\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9699e7c4-0b8f-4b62-9dbd-634ad7051599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers.setup\n",
    "importlib.reload(helpers.setup)\n",
    "from helpers.setup import set_device, set_seeds, set_pandas_options, reset_pandas_options\n",
    "\n",
    "# Set the device\n",
    "device = set_device()\n",
    "\n",
    "# Set random seeds\n",
    "set_seeds(seed=42, device=device)\n",
    "\n",
    "# Pandas display setup to avoid truncation\n",
    "set_pandas_options()\n",
    "reset_pandas_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bfd66c-e14d-4ec5-8acb-1b1452d4906a",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17817c09-817b-4002-b102-0de4fcc784e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder already exists. Skipping download...\n",
      "Nothing to extract. Skipping...\n",
      "Directory data_10_10_80 already exists. Skipping ...\n",
      "Directory data_20_10_70 already exists. Skipping ...\n",
      "Directory data_30_10_60 already exists. Skipping ...\n",
      "Directory data_70_20_10 already exists. Skipping ...\n",
      "Dataset splits generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import helpers.acquisition\n",
    "importlib.reload(helpers.acquisition)\n",
    "from helpers.acquisition import create_dataset\n",
    "\n",
    "url = \"https://data.mendeley.com/public-files/datasets/tywbtsjrjv/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/file_downloaded\"\n",
    "data_dir = \"data\"\n",
    "zip_path = os.path.join(data_dir, \"data_compressed.zip\")\n",
    "extracted_dir = \"Plant_leave_diseases_dataset_without_augmentation\"\n",
    "splits = {\n",
    "    'data_10_10_80': [0.1, 0.1, 0.8], #train 10% test 10% holdout 80%\n",
    "    'data_20_10_70': [0.2, 0.1, 0.7],\n",
    "    'data_30_10_60': [0.3, 0.1, 0.6],\n",
    "    'data_70_20_10': [0.7, 0.2, 0.1]\n",
    "}\n",
    "\n",
    "create_dataset(url, zip_path, splits, data_dir, extracted_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b591303-b7e6-489c-8f21-fd455d7df485",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64bfdc0-cfca-4402-8fbb-50f4f241cbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>image_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>split_type</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">data_10_10_80</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">holdout</th>\n",
       "      <th>Apple___Apple_scab</th>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple___Black_rot</th>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple___Cedar_apple_rust</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple___healthy</th>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Background_without_leaves</th>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">data_70_20_10</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">train</th>\n",
       "      <th>Tomato___Spider_mites Two-spotted_spider_mite</th>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tomato___Target_Spot</th>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tomato___Tomato_Yellow_Leaf_Curl_Virus</th>\n",
       "      <td>3749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tomato___Tomato_mosaic_virus</th>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tomato___healthy</th>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        image_count\n",
       "dataset       split_type class                                                     \n",
       "data_10_10_80 holdout    Apple___Apple_scab                                     504\n",
       "                         Apple___Black_rot                                      497\n",
       "                         Apple___Cedar_apple_rust                               221\n",
       "                         Apple___healthy                                       1317\n",
       "                         Background_without_leaves                              915\n",
       "...                                                                             ...\n",
       "data_70_20_10 train      Tomato___Spider_mites Two-spotted_spider_mite         1173\n",
       "                         Tomato___Target_Spot                                   982\n",
       "                         Tomato___Tomato_Yellow_Leaf_Curl_Virus                3749\n",
       "                         Tomato___Tomato_mosaic_virus                           261\n",
       "                         Tomato___healthy                                      1113\n",
       "\n",
       "[468 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import helpers.exploration\n",
    "importlib.reload(helpers.exploration)\n",
    "from helpers.exploration import traverse_dirs\n",
    "\n",
    "data_dir_names = list(splits.keys())\n",
    "classes_df = traverse_dirs(data_dir_names)\n",
    "classes_df = classes_df.groupby([\"dataset\", \"split_type\", \"class\"]).sum()\n",
    "classes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6c081-0d34-4103-81db-e41b5767da9b",
   "metadata": {},
   "source": [
    "## Data Preparation and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fce69f3-eba5-44c8-a957-d6f2de0e39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers.preparation\n",
    "importlib.reload(helpers.preparation)\n",
    "from helpers.preparation import create_dataloaders\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(264, 264),\n",
    "    ToTensorV2(),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "train_dataloader_10_10_80_aug, test_dataloader_10_10_80 = create_dataloaders(\"data_10_10_80/train\", \n",
    "                                                                         \"data_10_10_80/test\",\n",
    "                                                                         test_transform,\n",
    "                                                                         batch_size=BATCH_SIZE,\n",
    "                                                                         num_workers=NUM_WORKERS,\n",
    "                                                                         with_augmentation=True\n",
    "                                                                        )\n",
    "\n",
    "train_dataloader_10_10_80, test_dataloader_10_10_80 = create_dataloaders(\"data_10_10_80/train\", \n",
    "                                                                         \"data_10_10_80/test\",\n",
    "                                                                         test_transform,\n",
    "                                                                         batch_size=BATCH_SIZE,\n",
    "                                                                         num_workers=NUM_WORKERS,\n",
    "                                                                         with_augmentation=True\n",
    "                                                                        )\n",
    "\n",
    "train_dataloader_20_10_70_aug, test_dataloader_20_10_70 = create_dataloaders(\"data_20_10_70/train\", \n",
    "                                                                         \"data_20_10_70/test\",\n",
    "                                                                         test_transform,\n",
    "                                                                         batch_size=BATCH_SIZE,\n",
    "                                                                         num_workers=NUM_WORKERS,\n",
    "                                                                         with_augmentation=True\n",
    "                                                                        )\n",
    "\n",
    "train_dataloader_20_10_70, test_dataloader_20_10_70 = create_dataloaders(\"data_20_10_70/train\", \n",
    "                                                                         \"data_20_10_70/test\",\n",
    "                                                                         test_transform,\n",
    "                                                                         batch_size=BATCH_SIZE,\n",
    "                                                                         num_workers=NUM_WORKERS,\n",
    "                                                                         with_augmentation=True\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48e1ff2b-8232-4c42-b73f-31b2d9215333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 173, 173)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader_10_10_80_aug), len(train_dataloader_10_10_80), len(test_dataloader_10_10_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dfa5ce0-aea1-4cb5-951f-f76e59cc89a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347, 347, 173)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader_20_10_70_aug), len(train_dataloader_20_10_70), len(test_dataloader_20_10_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fea539-e6cd-4404-9338-cf13fcf8c762",
   "metadata": {},
   "source": [
    "## Data Augmentation with GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7b45d2-a9e4-43c4-a004-6bd3d6a8f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN and NoGAN\n",
    "\n",
    "# Data Augmentation\n",
    "\n",
    "# Different data splits \n",
    "    # 10% train 10% test 80% holdout (GAN and NoGAN)\n",
    "    # 20% train 10% test 70% holdout (GAN and NoGAN)\n",
    "    # 30% train 10% test 60% holdout (GAN and NoGAN)\n",
    "    # 70% train 20% test 10% holdout (GAN and NoGAN) - To be used only after experiment tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15792bc0-05f3-4524-ac66-72359f3649a9",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad8c341-e715-4068-bb0d-15733844d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Pre-trained Models\n",
    "    # EfficientNetB0 - as the highest performing overall in Hassan et al. 99.56%\n",
    "    # ViT - transformer based approach\n",
    "\n",
    "# Create the architecture for my own model\n",
    "    # Combine EfficientNetB0 with Attention blocks like in Thakur et al. (2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532577d-9da2-4371-b6ae-75cd6f1df2b9",
   "metadata": {},
   "source": [
    "## Model Training and Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f05fd9-a9f3-4793-91d0-7f55a94dc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Summary Writer\n",
    "\n",
    "# Train Model while recording experiment run and saving models\n",
    "    # different epochs, learning rates and dropout rates\n",
    "\n",
    "# Display tensorboard and select highest performing model to train further\n",
    "\n",
    "    #### MAYBE EXPLORE ML FLOW if time allows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e9dc5-34e6-41d7-901d-4e9638b45840",
   "metadata": {},
   "source": [
    "## Model Selection and Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c351fc31-6bc9-481a-bcfa-1e7e8a155b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the most promising model \n",
    "\n",
    "# Train it on 70% train 20% test 10% holdout (either GAN or no GAN depending on which performed better)\n",
    "\n",
    "# Calculate accuracy, precision, recall for the model (+ confusion matrix?)\n",
    "\n",
    "# Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e1800-d314-4f2a-a980-97497cfaee2f",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbbcec4d-c2f5-4181-a849-d876a182c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set and display\n",
    "\n",
    "# Predict on holdout set and display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a58b78c-9cb9-4414-84b9-54531f9b773a",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (dl-udemy-env)",
   "language": "python",
   "name": "dl-udemy-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
